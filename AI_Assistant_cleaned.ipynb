{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SakshamDataWizard/AI_Assistant/blob/main/AI_Assistant_cleaned.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIvSSW25lAKd"
      },
      "source": [
        "**AI - ASSISTANT for Learning and recommendations**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DuUITDy3L7gW",
        "outputId": "66da67f9-2001-485e-a5d1-f06328ed7fe9"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.11.9' requires the ipykernel package.\n",
            "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '\"c:/Users/saksham bhardwaj/AppData/Local/Microsoft/WindowsApps/python3.11.exe\" -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "!pip install scikit-learn pandas numpy matplotlib seaborn joblib\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
        "import joblib\n",
        "\n",
        "print(\"âœ… Setup complete.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kixKyT4Bit9x"
      },
      "outputs": [],
      "source": [
        "data = pd.DataFrame({\n",
        "    'hours_studied': [1, 2, 3, 2.5, 5, 8, 7, 6],\n",
        "    'attendance_pct': [50, 60, 70, 65, 90, 95, 85, 80],\n",
        "    'passed': [0, 0, 0, 0, 1, 1, 1, 1]\n",
        "})\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oqp3dfMClTRz"
      },
      "outputs": [],
      "source": [
        "X = data[['hours_studied', 'attendance_pct']]\n",
        "y = data['passed']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "y_prob = model.predict_proba(X_test)[:,1]\n",
        "print(\"ROC AUC:\", roc_auc_score(y_test, y_prob))\n",
        "\n",
        "\n",
        "joblib.dump(model, '/content/logreg_passfail.pkl')\n",
        "print(\"âœ… Model saved: logreg_passfail.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YPfCRh8Mlm_B"
      },
      "outputs": [],
      "source": [
        "score_data = pd.DataFrame({\n",
        "    'time_per_question_sec': [30, 45, 60, 20, 80, 35, 55, 40],\n",
        "    'past_score': [50, 60, 55, 70, 80, 65, 75, 68],\n",
        "    'difficulty': [2, 3, 2, 1, 4, 3, 4, 3],\n",
        "    'score': [55, 63, 58, 72, 85, 67, 78, 70]\n",
        "})\n",
        "score_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AxNrqLk9lsP7"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "X = score_data[['time_per_question_sec', 'past_score', 'difficulty']]\n",
        "y = score_data['score']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "rf = RandomForestRegressor(random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "rf_pred = rf.predict(X_test)\n",
        "\n",
        "lr = LinearRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "lr_pred = lr.predict(X_test)\n",
        "\n",
        "print(\"Random Forest:\")\n",
        "print(\"MAE:\", mean_absolute_error(y_test, rf_pred))\n",
        "print(\"RMSE:\", mean_squared_error(y_test, rf_pred))\n",
        "\n",
        "print(\"\\n Linear Regression:\")\n",
        "print(\"MAE:\", mean_absolute_error(y_test, lr_pred))\n",
        "print(\"RMSE:\", mean_squared_error(y_test, lr_pred))\n",
        "\n",
        "joblib.dump(rf, '/content/rf_score_predictor.pkl')\n",
        "joblib.dump(lr, '/content/lr_score_predictor.pkl')\n",
        "print(\"âœ… Models saved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60FY6yGpmB4L"
      },
      "outputs": [],
      "source": [
        "importances = rf.feature_importances_\n",
        "features = X.columns\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.barplot(x=importances, y=features)\n",
        "plt.title('Feature Importance - Random Forest')\n",
        "plt.xlabel('Importance')\n",
        "plt.ylabel('Feature')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-GnkoenmhiR"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "cluster_data = pd.DataFrame({\n",
        "    'time_on_topic': [20, 30, 40, 60, 15, 25, 70, 10],\n",
        "    'avg_score': [60, 65, 70, 85, 55, 62, 90, 50],\n",
        "    'num_attempts': [3, 2, 4, 1, 5, 3, 1, 6],\n",
        "    'response_time': [10, 12, 15, 5, 20, 10, 6, 25]\n",
        "})\n",
        "cluster_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5CZ9fAiemmZN"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "scaled_features = scaler.fit_transform(cluster_data)\n",
        "\n",
        "kmeans = KMeans(n_clusters=3, random_state=42)\n",
        "cluster_labels = kmeans.fit_predict(scaled_features)\n",
        "\n",
        "cluster_data['cluster'] = cluster_labels\n",
        "\n",
        "score = silhouette_score(scaled_features, cluster_labels)\n",
        "print(f\"Silhouette Score: {score:.3f}\")\n",
        "print(cluster_data)\n",
        "\n",
        "joblib.dump(kmeans, '/content/kmeans_learning_style.pkl')\n",
        "print(\"âœ… KMeans model saved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8YUdK0Nm3Me"
      },
      "outputs": [],
      "source": [
        "!pip install xgboost\n",
        "\n",
        "import xgboost as xgb\n",
        "\n",
        "dropout_data = pd.DataFrame({\n",
        "    'video_watch_count': [10, 20, 5, 0, 30, 25, 2, 3],\n",
        "    'forum_posts': [1, 2, 0, 0, 4, 3, 0, 0],\n",
        "    'problem_attempts': [5, 10, 2, 1, 15, 12, 1, 0],\n",
        "    'last_active_days': [2, 1, 7, 14, 1, 2, 10, 20],\n",
        "    'dropout_flag': [0, 0, 1, 1, 0, 0, 1, 1]\n",
        "})\n",
        "dropout_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0QWm1bugm8Fm"
      },
      "outputs": [],
      "source": [
        "X = dropout_data.drop('dropout_flag', axis=1)\n",
        "y = dropout_data['dropout_flag']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Save\n",
        "joblib.dump(model, '/content/xgb_dropout_predictor.pkl')\n",
        "print(\"âœ… XGBoost dropout model saved.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K06ceWECnTNH"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train = X_train.reshape(-1, 28, 28, 1) / 255.0\n",
        "X_test = X_test.reshape(-1, 28, 28, 1) / 255.0\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)),\n",
        "    MaxPooling2D((2,2)),\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, epochs=3, validation_split=0.2)\n",
        "\n",
        "model.save('/content/mnist_cnn.h5')\n",
        "print(\"âœ… CNN model saved.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C47hPSXyndNf"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Input, Bidirectional\n",
        "\n",
        "texts = [\n",
        "    \"The climate is changing rapidly\",\n",
        "    \"Photosynthesis is crucial to plant growth\",\n",
        "    \"Newtonâ€™s laws describe motion\",\n",
        "    \"The French Revolution changed history\"\n",
        "]\n",
        "labels = [0, 1, 2, 3]  # 4 classes (env, bio, physics, history)\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "X = pad_sequences(sequences, maxlen=10)\n",
        "y = to_categorical(labels)\n",
        "\n",
        "input_ = Input(shape=(10,))\n",
        "x = Embedding(input_dim=50, output_dim=8)(input_)\n",
        "x = Bidirectional(LSTM(16))(x)\n",
        "x = Dense(4, activation='softmax')(x)\n",
        "\n",
        "model = Model(input_, x)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X, y, epochs=10)\n",
        "\n",
        "model.save('/content/bilstm_topic_classifier.h5')\n",
        "print(\"âœ… BiLSTM model saved.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cnu73mjoCcy"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "summarizer = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-12-6\")\n",
        "\n",
        "text = \"\"\"\n",
        "Artificial Intelligence is transforming the educational landscape. It allows personalized learning experiences, automates grading, and provides real-time feedback to students and educators alike.\n",
        "\"\"\"\n",
        "\n",
        "summary = summarizer(text, max_length=40, min_length=10, do_sample=False)\n",
        "print(\"Summary:\", summary[0]['summary_text'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q7HltQhssHN4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "num_students = 300\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    \"study_hours\": np.clip(np.random.normal(loc=4, scale=2, size=num_students), 0, 10),\n",
        "    \"attendance\": np.clip(np.random.normal(loc=80, scale=10, size=num_students), 50, 100),\n",
        "    \"previous_scores\": np.clip(np.random.normal(loc=70, scale=15, size=num_students), 0, 100)\n",
        "})\n",
        "\n",
        "df[\"final_score\"] = (\n",
        "    0.4 * df[\"study_hours\"] * 10 +\n",
        "    0.3 * df[\"attendance\"] +\n",
        "    0.3 * df[\"previous_scores\"] +\n",
        "    np.random.normal(0, 5, num_students)\n",
        ") / 2\n",
        "df[\"final_score\"] = df[\"final_score\"].clip(0, 100)\n",
        "\n",
        "df[\"dropout_risk\"] = ((df[\"attendance\"] < 65) | (df[\"final_score\"] < 50)).astype(int)\n",
        "\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "saH2R9xKs4Xm"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X = df[[\"study_hours\", \"attendance\", \"previous_scores\"]]\n",
        "y_score = df[\"final_score\"]\n",
        "y_dropout = df[\"dropout_risk\"]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "score_regressor = LinearRegression()\n",
        "score_regressor.fit(X_scaled, y_score)\n",
        "\n",
        "dropout_classifier = RandomForestClassifier(random_state=42)\n",
        "dropout_classifier.fit(X_scaled, y_dropout)\n",
        "\n",
        "cluster_model = KMeans(n_clusters=3, random_state=42)\n",
        "cluster_model.fit(X_scaled)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-p6rpVVvoLft"
      },
      "outputs": [],
      "source": [
        "!pip install streamlit scikit-learn pandas matplotlib seaborn joblib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0oxMVQqepwkm"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(score_regressor, 'score_regressor.pkl')\n",
        "joblib.dump(dropout_classifier, 'dropout_classifier.pkl')\n",
        "joblib.dump(cluster_model, 'student_cluster_model.pkl')\n",
        "joblib.dump(scaler, 'scaler.pkl')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wv1bV9D-tfpO"
      },
      "outputs": [],
      "source": [
        "%%writefile AI_Assistant_app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import joblib\n",
        "import numpy as np\n",
        "\n",
        "score_model = joblib.load('score_regressor.pkl')\n",
        "dropout_model = joblib.load('dropout_classifier.pkl')\n",
        "cluster_model = joblib.load('student_cluster_model.pkl')\n",
        "scaler = joblib.load('scaler.pkl')\n",
        "\n",
        "st.set_page_config(page_title=\"AI Learning Assistant\", layout=\"wide\")\n",
        "\n",
        "st.title(\"ðŸŽ“ AI-Powered Personalized Learning Assistant\")\n",
        "\n",
        "with st.form(\"student_form\"):\n",
        "    st.subheader(\"Enter Student Details\")\n",
        "\n",
        "    study_hours = st.number_input(\"Daily Study Hours\", min_value=0.0, max_value=24.0, step=0.5)\n",
        "    attendance = st.slider(\"Attendance (%)\", 0, 100, 75)\n",
        "    previous_scores = st.number_input(\"Average Previous Scores (0-100)\", min_value=0.0, max_value=100.0)\n",
        "\n",
        "    submitted = st.form_submit_button(\"Predict\")\n",
        "\n",
        "if submitted:\n",
        "    input_data = pd.DataFrame([[study_hours, attendance, previous_scores]],\n",
        "                              columns=[\"study_hours\", \"attendance\", \"previous_scores\"])\n",
        "\n",
        "    scaled_data = scaler.transform(input_data)\n",
        "\n",
        "    score_pred = score_model.predict(scaled_data)[0]\n",
        "    dropout_risk = dropout_model.predict(scaled_data)[0]\n",
        "    cluster = cluster_model.predict(scaled_data)[0]\n",
        "\n",
        "    st.markdown(f\"### ðŸ“Š Predicted Score: **{score_pred:.2f}**\")\n",
        "    st.markdown(f\"### âš ï¸ Dropout Risk: {'Yes' if dropout_risk else 'No'}\")\n",
        "    st.markdown(f\"### ðŸ§  Learning Style Cluster: **Cluster {cluster}**\")\n",
        "\n",
        "    if cluster == 0:\n",
        "        st.info(\"ðŸ’¡ Tip: Visual learner â€“ use diagrams and charts.\")\n",
        "    elif cluster == 1:\n",
        "        st.info(\"ðŸŽ§ Tip: Auditory learner â€“ benefit from lectures or podcasts.\")\n",
        "    else:\n",
        "        st.info(\"ðŸ“ Tip: Kinesthetic learner â€“ hands-on activities work best.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ic99L6d7veZ8"
      },
      "outputs": [],
      "source": [
        "!pip install streamlit pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLyiy6Dlwc7d"
      },
      "outputs": [],
      "source": [
        "! streamlit run AI_Assistant_app.py & npx localtunnel --port 8501"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}